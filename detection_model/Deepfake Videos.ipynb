{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415a836a-39ea-4ef5-9418-6cc3edd5183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9580e62-2dad-48b0-93bc-4ced7e872c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "class DeepfakeDetector:\n",
    "    def __init__(self, model_name=\"shylhy/videomae-large-finetuned-deepfake-subset\"):\n",
    "        \"\"\"\n",
    "        Initialize the deepfake detector with the VideoMAE model\n",
    "        \"\"\"\n",
    "        print(\"Loading model and processor...\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load the model and image processor\n",
    "        self.model = VideoMAEForVideoClassification.from_pretrained(model_name)\n",
    "        self.image_processor = VideoMAEImageProcessor.from_pretrained(model_name)\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get model configuration\n",
    "        self.num_frames = self.model.config.num_frames\n",
    "        self.image_mean = torch.tensor(self.image_processor.image_mean)\n",
    "        self.image_std = torch.tensor(self.image_processor.image_std)\n",
    "        \n",
    "        # Get image size\n",
    "        if \"shortest_edge\" in self.image_processor.size:\n",
    "            self.height = self.width = self.image_processor.size[\"shortest_edge\"]\n",
    "        else:\n",
    "            self.height = self.image_processor.size[\"height\"]\n",
    "            self.width = self.image_processor.size[\"width\"]\n",
    "        \n",
    "        print(f\"Model loaded on {self.device}\")\n",
    "        print(f\"Expected frames: {self.num_frames}\")\n",
    "        print(f\"Expected resolution: {self.height}x{self.width}\")\n",
    "\n",
    "    def uniform_temporal_subsample(self, frames, num_samples):\n",
    "        \"\"\"\n",
    "        Uniformly subsample frames from video\n",
    "        \"\"\"\n",
    "        total_frames = len(frames)\n",
    "        if total_frames <= num_samples:\n",
    "            # If we have fewer frames than needed, repeat the last frame\n",
    "            indices = list(range(total_frames))\n",
    "            while len(indices) < num_samples:\n",
    "                indices.append(total_frames - 1)\n",
    "        else:\n",
    "            # Uniformly sample frames\n",
    "            indices = np.linspace(0, total_frames - 1, num_samples, dtype=int)\n",
    "        \n",
    "        return [frames[i] for i in indices]\n",
    "\n",
    "    def preprocess_video(self, video_path):\n",
    "        \"\"\"\n",
    "        Preprocess video for the model without PyTorchVideo dependency\n",
    "        \"\"\"\n",
    "        # Read video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Convert BGR to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        if len(frames) == 0:\n",
    "            raise ValueError(f\"Could not read any frames from {video_path}\")\n",
    "        \n",
    "        print(f\"Total frames in video: {len(frames)}\")\n",
    "        \n",
    "        # Uniformly sample the required number of frames\n",
    "        sampled_frames = self.uniform_temporal_subsample(frames, self.num_frames)\n",
    "        \n",
    "        # Convert to tensor and preprocess\n",
    "        processed_frames = []\n",
    "        \n",
    "        # Define transforms\n",
    "        resize_transform = transforms.Resize((self.height, self.width))\n",
    "        \n",
    "        for frame in sampled_frames:\n",
    "            # Convert to tensor and normalize to [0, 1]\n",
    "            frame_tensor = torch.from_numpy(frame).float() / 255.0\n",
    "            \n",
    "            # Rearrange from HWC to CHW\n",
    "            frame_tensor = frame_tensor.permute(2, 0, 1)\n",
    "            \n",
    "            # Resize\n",
    "            frame_tensor = resize_transform(frame_tensor)\n",
    "            \n",
    "            # Normalize with model's expected mean and std\n",
    "            frame_tensor = transforms.functional.normalize(\n",
    "                frame_tensor, \n",
    "                self.image_mean.tolist(), \n",
    "                self.image_std.tolist()\n",
    "            )\n",
    "            \n",
    "            processed_frames.append(frame_tensor)\n",
    "        \n",
    "        # Stack frames: (num_frames, channels, height, width)\n",
    "        video_tensor = torch.stack(processed_frames)\n",
    "        \n",
    "        return video_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    def predict_single_video(self, video_path):\n",
    "        \"\"\"\n",
    "        Predict if a single video is deepfake or real\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Preprocess video\n",
    "            pixel_values = self.preprocess_video(video_path)\n",
    "            pixel_values = pixel_values.to(self.device)\n",
    "            \n",
    "            # Run inference\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(pixel_values=pixel_values)\n",
    "                logits = outputs.logits\n",
    "                probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Get prediction\n",
    "            predicted_class_idx = logits.argmax(-1).item()\n",
    "            confidence = probabilities.max().item()\n",
    "            \n",
    "            # Get all class probabilities\n",
    "            all_probs = probabilities.cpu().numpy().flatten()\n",
    "            \n",
    "            # Map to labels - check model config for actual labels\n",
    "            if hasattr(self.model.config, 'id2label') and self.model.config.id2label:\n",
    "                label = self.model.config.id2label[predicted_class_idx]\n",
    "            else:\n",
    "                # Fallback assumption: 0=real, 1=fake\n",
    "                label = \"FAKE\" if predicted_class_idx == 1 else \"REAL\"\n",
    "            \n",
    "            return {\n",
    "                \"video_path\": video_path,\n",
    "                \"prediction\": label,\n",
    "                \"confidence\": confidence,\n",
    "                \"predicted_class_idx\": predicted_class_idx,\n",
    "                \"all_probabilities\": all_probs.tolist(),\n",
    "                \"raw_logits\": logits.cpu().numpy().flatten().tolist()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"video_path\": video_path,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def predict_batch(self, video_paths):\n",
    "        \"\"\"\n",
    "        Predict multiple videos\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for i, video_path in enumerate(video_paths):\n",
    "            print(f\"Processing video {i+1}/{len(video_paths)}: {os.path.basename(video_path)}\")\n",
    "            result = self.predict_single_video(video_path)\n",
    "            results.append(result)\n",
    "            \n",
    "            if \"error\" not in result:\n",
    "                print(f\"  -> {result['prediction']} (confidence: {result['confidence']:.3f})\")\n",
    "            else:\n",
    "                print(f\"  -> ERROR: {result['error']}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def predict_directory(self, directory_path, extensions=None):\n",
    "        \"\"\"\n",
    "        Predict all videos in a directory\n",
    "        \"\"\"\n",
    "        if extensions is None:\n",
    "            extensions = ['.mp4']\n",
    "        \n",
    "        directory = Path(directory_path)\n",
    "        video_files = []\n",
    "        \n",
    "        for ext in extensions:\n",
    "            video_files.extend(directory.glob(f\"*{ext}\"))\n",
    "            video_files.extend(directory.glob(f\"*{ext.upper()}\"))\n",
    "        \n",
    "        video_paths = [str(path) for path in video_files]\n",
    "        print(f\"Found {len(video_paths)} video files\")\n",
    "        \n",
    "        if len(video_paths) == 0:\n",
    "            print(\"No video files found in the directory!\")\n",
    "            return []\n",
    "        \n",
    "        return self.predict_batch(video_paths)\n",
    "\n",
    "    def save_results(self, results, output_file=\"deepfake_results.json\"):\n",
    "        \"\"\"\n",
    "        Save results to JSON file\n",
    "        \"\"\"\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    def print_summary(self, results):\n",
    "        \"\"\"\n",
    "        Print summary of results\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            print(\"No results to summarize.\")\n",
    "            return\n",
    "        \n",
    "        total_videos = len(results)\n",
    "        successful_predictions = len([r for r in results if \"error\" not in r])\n",
    "        errors = total_videos - successful_predictions\n",
    "        \n",
    "        print(f\"\\n--- SUMMARY ---\")\n",
    "        print(f\"Total videos processed: {total_videos}\")\n",
    "        print(f\"Successful predictions: {successful_predictions}\")\n",
    "        print(f\"Errors: {errors}\")\n",
    "        \n",
    "        if successful_predictions > 0:\n",
    "            successful_results = [r for r in results if \"error\" not in r]\n",
    "            fake_count = len([r for r in successful_results if \"FAKE\" in r['prediction'].upper()])\n",
    "            real_count = successful_predictions - fake_count\n",
    "            \n",
    "            print(f\"Predicted as FAKE: {fake_count}\")\n",
    "            print(f\"Predicted as REAL: {real_count}\")\n",
    "            \n",
    "            avg_confidence = sum(r['confidence'] for r in successful_results) / len(successful_results)\n",
    "            print(f\"Average confidence: {avg_confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75ec8b37-7e91-4b18-8c56-73e2294ef67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and processor...\n",
      "Model loaded on cpu\n",
      "Expected frames: 32\n",
      "Expected resolution: 224x224\n"
     ]
    }
   ],
   "source": [
    "detector = DeepfakeDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5ed927a-1638-41f5-877b-1a1771885c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example 3: Directory Prediction ===\n",
      "Found 4 video files\n",
      "Processing video 1/4: pyramids.mp4\n",
      "Total frames in video: 237\n",
      "  -> real (confidence: 0.832)\n",
      "Processing video 2/4: vlog bible.mp4\n",
      "Total frames in video: 1333\n",
      "  -> real (confidence: 0.798)\n",
      "Processing video 3/4: pyramids.mp4\n",
      "Total frames in video: 237\n",
      "  -> real (confidence: 0.832)\n",
      "Processing video 4/4: vlog bible.mp4\n",
      "Total frames in video: 1333\n",
      "  -> real (confidence: 0.798)\n",
      "\n",
      "--- SUMMARY ---\n",
      "Total videos processed: 4\n",
      "Successful predictions: 4\n",
      "Errors: 0\n",
      "Predicted as FAKE: 0\n",
      "Predicted as REAL: 4\n",
      "Average confidence: 0.815\n",
      "Results saved to directory_results.json\n",
      "\n",
      "Model configuration:\n",
      "- Number of classes: 2\n",
      "- Labels: {0: 'deepfake', 1: 'real'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Example 3: Directory Prediction ===\")\n",
    "results = detector.predict_directory(\"./videos\")\n",
    "detector.print_summary(results)\n",
    "detector.save_results(results, \"directory_results.json\")\n",
    "\n",
    "print(\"\\nModel configuration:\")\n",
    "print(f\"- Number of classes: {detector.model.config.num_labels}\")\n",
    "if hasattr(detector.model.config, 'id2label') and detector.model.config.id2label:\n",
    "    print(f\"- Labels: {detector.model.config.id2label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be413a-c636-4536-b05b-b49652491286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
